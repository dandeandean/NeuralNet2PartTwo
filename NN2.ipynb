{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c5e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36727740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralMMAgent(object):\n",
    "    '''\n",
    "    Class to for Neural Net Agents that compete in the Mob task\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_in_nodes, num_hid_nodes, num_hid_layers, num_out_nodes, \\\n",
    "                learning_rate = 0.2, max_epoch=10000, min_sse=.01, momentum=0, \\\n",
    "                creation_function=None, activation_function=None, random_seed=1):\n",
    "        '''\n",
    "        Arguments:\n",
    "            num_in_nodes -- total # of input nodes for Neural Net\n",
    "            num_hid_nodes -- total # of hidden nodes for each hidden layer\n",
    "                in the Neural Net\n",
    "            num_hid_layers -- total # of hidden layers for Neural Net\n",
    "            num_out_nodes -- total # of output layers for Neural Net\n",
    "            learning_rate -- learning rate to be used when propogating error\n",
    "            max_epoch -- maximum number of epochs for our NN to run during learning\n",
    "            min_sse -- minimum SSE that we will use as a stopping point\n",
    "            momentum -- Momentum term used for learning\n",
    "            creation_function -- function that will be used to create the\n",
    "                neural network given the input\n",
    "            activation_function -- list of two functions:\n",
    "                1st function will be used by network to determine activation given a weighted summed input\n",
    "                2nd function will be the derivative of the 1st function\n",
    "            random_seed -- used to seed object random attribute.\n",
    "                This ensures that we can reproduce results if wanted\n",
    "        '''\n",
    "        assert num_in_nodes > 0 and num_hid_layers > 0 and num_hid_nodes and num_out_nodes > 0, \"Illegal number of input, hidden, or output layers!\"\n",
    "        self.num_in_nodes = num_in_nodes\n",
    "        self.num_hid_nodes = num_hid_nodes\n",
    "        self.num_hid_layers = num_hid_layers\n",
    "        self.num_out_nodes = num_out_nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epoch = max_epoch\n",
    "        self.min_sse = min_sse\n",
    "        self.momentum = momentum\n",
    "        self.creation_function = creation_function\n",
    "        self.activation_function = activation_function\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        #WE CAN SIMPLY FILL OUT THESE VALUES LATER AS WE CALCULATE THEM, BUT WE INIT HERE\n",
    "        self.weights = self._construct_ligaments()\n",
    "        self.weight_ds = self._construct_ligaments()\n",
    "        \n",
    "        self.activations = self._construct_skeleton()\n",
    "        self.errors = self._construct_skeleton()\n",
    "        self.biases = self._construct_skeleton()\n",
    "        self.bias_ds = self._construct_skeleton()\n",
    "                \n",
    "    ##################################################################################################\n",
    "    #ACCESSORS\n",
    "    def get_weights(self):\n",
    "        return (self.weights)\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights\n",
    "\n",
    "    def get_biases(self):\n",
    "        return (self.biases)\n",
    "\n",
    "    def set_biases(self, bias):\n",
    "        self.bias = biases\n",
    "    \n",
    "    def set_thetas(self, thetas):\n",
    "        self.thetas = thetas\n",
    "    @staticmethod\n",
    "    def sigmoid_af(summed_input):\n",
    "        #Sigmoid function\n",
    "        e_to_the = numpy.exp #pythonic\n",
    "        denom = 1+e_to_the(-summed_input)\n",
    "        return 1/denom \n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_af_deriv(sig_output):\n",
    "        #the derivative of the sigmoid function\"\n",
    "        return sig_output * (1-sig_output)\n",
    "\n",
    "    def matrixify_weigths(self,layer):\n",
    "        layer_in_question = self.weights[layer]\n",
    "        cols = list()\n",
    "        for i in range(len(layer_in_question)//self.num_hid_nodes):\n",
    "            cols.append(self._get_incoming_weights(layer+1,i))\n",
    "        return cols\n",
    "    \n",
    "        \n",
    "    def _construct_skeleton(self):\n",
    "        #returns a 2d array that represents each node, inits to all zeros\n",
    "        #the middle layers\n",
    "        out=numpy.zeros((self.num_hid_layers,self.num_hid_nodes)).tolist()\n",
    "        #the first layer \n",
    "        out.insert(0,[0.0] * self.num_in_nodes)\n",
    "        #the last layer\n",
    "        out.append([0.0] * self.num_out_nodes)\n",
    "        return out\n",
    "    ##################################################################################################\n",
    "    #FEED FORWARD\n",
    "    def _feed_forward(self, input_list, row):\n",
    "        '''Used to feedforward input and calculate all activation values\n",
    "            Arguments:\n",
    "                input_list -- a list of possible input values\n",
    "                row -- the row from that input_list that we should use\n",
    "            Outputs:\n",
    "                list of activation values\n",
    "        '''\n",
    "        return self.__feedforward(input_list[row])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __feedforward(self,inp):\n",
    "        #simply shoe the input layer in there\n",
    "        self.activations = [ [float(i) for i in inp] ]\n",
    "        # with biases\n",
    "        for i in range(len(self.activations[0])): self.activations[0][i] += self.bias[0][i]\n",
    "        for i in range(self.num_hid_layers+1):\n",
    "            # change the order of the weights so we can take the dot product with the previous layer of activations \n",
    "            self.activations.append(NeuralMMAgent.sigmoid_af(numpy.dot(numpy.matrix(self.matrixify_weigths(i)),self.activations[-1])+self.bias[i+1]).tolist()[0])\n",
    "        return self.activations\n",
    "    \n",
    "    def _get_incoming_weights(self,layer_index,node_index):\n",
    "        incoming_weights = list()\n",
    "        if not layer_index: return [] #zeroth layer is input should not have incoming weights\n",
    "                                      # is it a hidden node?                        or is it an output node?\n",
    "        depth = self.num_hid_nodes*(layer_index <= self.num_hid_layers) + self.num_out_nodes*(layer_index > self.num_hid_layers)\n",
    "        for i in range(node_index,len(self.weights[layer_index-1]),depth):\n",
    "            incoming_weights.append(self.weights[layer_index-1][i])\n",
    "        return incoming_weights\n",
    "\n",
    "    \n",
    "    def _get_outgoing_weights(self,layer_index,node_index):\n",
    "        if layer_index == self.num_hid_layers+1: return []\n",
    "        assert(len(self.weights[layer_index])>(node_index))\n",
    "        \n",
    "        outgoing_weights = list()\n",
    "        depth = self.num_hid_nodes*(layer_index <= self.num_hid_layers) + self.num_out_nodes*(layer_index > self.num_hid_layers)\n",
    "        if layer_index == self.num_hid_layers+1: return []\n",
    "        #a straightforward way of getting the # of nodes in the next layer \n",
    "        nodes_in_next_layer = self.num_hid_nodes*(layer_index+1 <= self.num_hid_layers) + self.num_out_nodes*(layer_index+1 > self.num_hid_layers)\n",
    "        for i in range(0,nodes_in_next_layer):\n",
    "            outgoing_weights.append(self.weights[layer_index][node_index*nodes_in_next_layer +i])\n",
    "        return outgoing_weights\n",
    "    ##################################################################################################\n",
    "    \n",
    "    def _construct_ligaments(self):\n",
    "        #returns a 2d array that represents the connections, inits to all zeros\n",
    "        #hidden nodes connections\n",
    "        out = numpy.zeros((self.num_hid_layers-1,self.num_hid_nodes**2)).tolist()\n",
    "        #input nodes to hidden nodes\n",
    "        out.insert(0,[0.0]*self.num_in_nodes*self.num_hid_nodes)\n",
    "        #last layer to output nodes connections\n",
    "        out.append([0.0]*self.num_hid_nodes*self.num_out_nodes)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb9292a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NeuralMMAgent(2,2,1,1)\n",
    "#Expected the first list in get_biases() of size 2, but got 0 instead, when your constructor is called on num_inp: 2, num_hid: 2, num_hid_layers: 1, num_out:1!\n",
    "#n.weights = [[-0.071, 0.078, 0.313, 0.323], [-0.34, 0.021]]\n",
    "#n.inputs = [[1,1]]\n",
    "#n.bias = [[0,0],[0,0],[0]]\n",
    "#n.outputs = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf11050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5667caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Failed: 1 != 0 : Expected the first list in get_weights() of size 4, but got 2 instead, when your constructor is called on num_inp: 2, num_hid: 2, num_hid_layers: 1, num_out:1!\n",
    "#Test Failed: 1 != 0 : Expected the second list in get_weights() of size 2, but got 4 instead, when your constructor is called on num_inp: 2, num_hid: 2, num_hid_layers: 1, num_out:1!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2302aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n._construct_ligaments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db979387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
